{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be07ff10",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-09T13:26:20.842202Z",
     "iopub.status.busy": "2024-09-09T13:26:20.841841Z",
     "iopub.status.idle": "2024-09-09T13:26:34.165325Z",
     "shell.execute_reply": "2024-09-09T13:26:34.164296Z"
    },
    "papermill": {
     "duration": 13.330652,
     "end_time": "2024-09-09T13:26:34.167781",
     "exception": false,
     "start_time": "2024-09-09T13:26:20.837129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data = pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\", encoding=\"utf8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99acb9ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:26:34.175587Z",
     "iopub.status.busy": "2024-09-09T13:26:34.175218Z",
     "iopub.status.idle": "2024-09-09T13:26:34.201393Z",
     "shell.execute_reply": "2024-09-09T13:26:34.200336Z"
    },
    "papermill": {
     "duration": 0.032549,
     "end_time": "2024-09-09T13:26:34.203657",
     "exception": false,
     "start_time": "2024-09-09T13:26:34.171108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  English words/sentences French words/sentences\n",
      "0                     Hi.                 Salut!\n",
      "1                    Run!                Cours !\n",
      "2                    Run!               Courez !\n",
      "3                    Who?                  Qui ?\n",
      "4                    Wow!             Ça alors !\n",
      "len de input_text 99999\n",
      "len de target_texts 99999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data.head())\n",
    "\n",
    "data = data[:99999]\n",
    "data = data.rename(columns={\"English words/sentences\": \"english\", \"French words/sentences\": \"french\"})\n",
    "\n",
    "# Extraire les colonnes\n",
    "input_texts = data['english'].tolist()\n",
    "target_texts = data['french'].tolist()\n",
    "\n",
    "print(\"len de input_text\", len(input_texts))\n",
    "print(\"len de target_texts\", len(target_texts))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280d432f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:26:34.210918Z",
     "iopub.status.busy": "2024-09-09T13:26:34.210606Z",
     "iopub.status.idle": "2024-09-09T13:26:34.913266Z",
     "shell.execute_reply": "2024-09-09T13:26:34.912455Z"
    },
    "papermill": {
     "duration": 0.708877,
     "end_time": "2024-09-09T13:26:34.915585",
     "exception": false,
     "start_time": "2024-09-09T13:26:34.206708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialiser les ensembles de caractères uniques\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "# Ajouter des tokens de début et de fin de séquence aux textes cibles\n",
    "target_texts = ['\\t' + text + '\\n' for text in target_texts]\n",
    "\n",
    "# Extraire les caractères uniques dans les textes d'entrée et de sortie\n",
    "for input_text, target_text in zip(input_texts, target_texts):\n",
    "    for char in input_text:\n",
    "        input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        target_characters.add(char)\n",
    "\n",
    "# Trier les caractères uniques\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_characters) \n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfae582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:26:34.923572Z",
     "iopub.status.busy": "2024-09-09T13:26:34.923239Z",
     "iopub.status.idle": "2024-09-09T13:26:43.937309Z",
     "shell.execute_reply": "2024-09-09T13:26:43.936458Z"
    },
    "papermill": {
     "duration": 9.020854,
     "end_time": "2024-09-09T13:26:43.939837",
     "exception": false,
     "start_time": "2024-09-09T13:26:34.918983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100  \n",
    "latent_dim = 256 \n",
    "num_samples = 10000\n",
    "\n",
    "# Préparer les données d'entrée et de sortie\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1:, input_token_index[\" \"]] = 1.0\n",
    "\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1:, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71992c",
   "metadata": {
    "papermill": {
     "duration": 0.002973,
     "end_time": "2024-09-09T13:26:43.946551",
     "exception": false,
     "start_time": "2024-09-09T13:26:43.943578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134c8c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:26:43.954192Z",
     "iopub.status.busy": "2024-09-09T13:26:43.953840Z",
     "iopub.status.idle": "2024-09-09T13:35:20.389338Z",
     "shell.execute_reply": "2024-09-09T13:35:20.388285Z"
    },
    "papermill": {
     "duration": 516.442171,
     "end_time": "2024-09-09T13:35:20.391873",
     "exception": false,
     "start_time": "2024-09-09T13:26:43.949702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - accuracy: 0.7474 - loss: 1.0729 - val_accuracy: 0.7558 - val_loss: 0.8221\n",
      "Epoch 2/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - accuracy: 0.8283 - loss: 0.5781 - val_accuracy: 0.7923 - val_loss: 0.6966\n",
      "Epoch 3/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.8543 - loss: 0.4871 - val_accuracy: 0.8165 - val_loss: 0.6146\n",
      "Epoch 4/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.8712 - loss: 0.4296 - val_accuracy: 0.8328 - val_loss: 0.5600\n",
      "Epoch 5/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.8841 - loss: 0.3861 - val_accuracy: 0.8454 - val_loss: 0.5150\n",
      "Epoch 6/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.8935 - loss: 0.3536 - val_accuracy: 0.8539 - val_loss: 0.4853\n",
      "Epoch 7/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9005 - loss: 0.3286 - val_accuracy: 0.8607 - val_loss: 0.4623\n",
      "Epoch 8/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9062 - loss: 0.3088 - val_accuracy: 0.8647 - val_loss: 0.4476\n",
      "Epoch 9/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9100 - loss: 0.2951 - val_accuracy: 0.8681 - val_loss: 0.4354\n",
      "Epoch 10/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9140 - loss: 0.2812 - val_accuracy: 0.8712 - val_loss: 0.4254\n",
      "Epoch 11/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9168 - loss: 0.2710 - val_accuracy: 0.8746 - val_loss: 0.4158\n",
      "Epoch 12/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9195 - loss: 0.2622 - val_accuracy: 0.8767 - val_loss: 0.4086\n",
      "Epoch 13/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9222 - loss: 0.2525 - val_accuracy: 0.8786 - val_loss: 0.4023\n",
      "Epoch 14/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9244 - loss: 0.2454 - val_accuracy: 0.8795 - val_loss: 0.3991\n",
      "Epoch 15/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9257 - loss: 0.2398 - val_accuracy: 0.8804 - val_loss: 0.3974\n",
      "Epoch 16/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9277 - loss: 0.2337 - val_accuracy: 0.8814 - val_loss: 0.3938\n",
      "Epoch 17/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9292 - loss: 0.2280 - val_accuracy: 0.8819 - val_loss: 0.3932\n",
      "Epoch 18/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9309 - loss: 0.2227 - val_accuracy: 0.8827 - val_loss: 0.3908\n",
      "Epoch 19/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9323 - loss: 0.2177 - val_accuracy: 0.8826 - val_loss: 0.3920\n",
      "Epoch 20/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9336 - loss: 0.2134 - val_accuracy: 0.8836 - val_loss: 0.3900\n",
      "Epoch 21/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9345 - loss: 0.2102 - val_accuracy: 0.8835 - val_loss: 0.3910\n",
      "Epoch 22/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9355 - loss: 0.2067 - val_accuracy: 0.8841 - val_loss: 0.3911\n",
      "Epoch 23/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9369 - loss: 0.2023 - val_accuracy: 0.8846 - val_loss: 0.3902\n",
      "Epoch 24/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9376 - loss: 0.1997 - val_accuracy: 0.8841 - val_loss: 0.3927\n",
      "Epoch 25/100\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9389 - loss: 0.1955 - val_accuracy: 0.8844 - val_loss: 0.3933\n"
     ]
    }
   ],
   "source": [
    "# Définir le modèle\n",
    "encoder_inputs = tf.keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = tf.keras.Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.3,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d644fe63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:35:21.550692Z",
     "iopub.status.busy": "2024-09-09T13:35:21.550290Z",
     "iopub.status.idle": "2024-09-09T13:35:21.556246Z",
     "shell.execute_reply": "2024-09-09T13:35:21.555348Z"
    },
    "papermill": {
     "duration": 0.563175,
     "end_time": "2024-09-09T13:35:21.558092",
     "exception": false,
     "start_time": "2024-09-09T13:35:20.994917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8efa474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T13:35:22.712076Z",
     "iopub.status.busy": "2024-09-09T13:35:22.711689Z",
     "iopub.status.idle": "2024-09-09T13:35:41.253824Z",
     "shell.execute_reply": "2024-09-09T13:35:41.252458Z"
    },
    "papermill": {
     "duration": 19.153167,
     "end_time": "2024-09-09T13:35:41.255893",
     "exception": false,
     "start_time": "2024-09-09T13:35:22.102726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Reste dans la boîte !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Reste dans la boîte !\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Qui avez-vous ?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Pourquoi est le mien !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Pas de chance !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Aidez-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute la porte !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Vas-y !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Vas-y !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Vas-y !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je vois le tien.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'essaie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = tf.keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = tf.keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n",
    "for seq_index in range(20):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 592212,
     "sourceId": 1067156,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 567.037006,
   "end_time": "2024-09-09T13:35:45.147300",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-09T13:26:18.110294",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
