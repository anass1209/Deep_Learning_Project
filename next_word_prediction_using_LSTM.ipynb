{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc556a2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:38.602163Z",
     "iopub.status.busy": "2024-09-05T17:47:38.601866Z",
     "iopub.status.idle": "2024-09-05T17:47:52.424031Z",
     "shell.execute_reply": "2024-09-05T17:47:52.422899Z"
    },
    "papermill": {
     "duration": 13.830707,
     "end_time": "2024-09-05T17:47:52.426517",
     "exception": false,
     "start_time": "2024-09-05T17:47:38.595810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 6956\n",
      "35 premier sequences: [[4073, 13, 24, 6, 539, 2492], [13, 24, 6, 539, 2492, 703], [24, 6, 539, 2492, 703, 12], [6, 539, 2492, 703, 12, 6], [539, 2492, 703, 12, 6, 1026], [2492, 703, 12, 6, 1026, 119], [703, 12, 6, 1026, 119, 7], [12, 6, 1026, 119, 7, 1263], [6, 1026, 119, 7, 1263, 3], [1026, 119, 7, 1263, 3, 6], [119, 7, 1263, 3, 6, 97], [7, 1263, 3, 6, 97, 381], [1263, 3, 6, 97, 381, 63], [3, 6, 97, 381, 63, 18], [6, 97, 381, 63, 18, 7], [97, 381, 63, 18, 7, 344], [381, 63, 18, 7, 344, 3], [63, 18, 7, 344, 3, 6], [18, 7, 344, 3, 6, 345], [7, 344, 3, 6, 345, 124], [344, 3, 6, 345, 124, 98], [3, 6, 345, 124, 98, 279], [6, 345, 124, 98, 279, 1], [345, 124, 98, 279, 1, 177], [124, 98, 279, 1, 177, 67], [98, 279, 1, 177, 67, 1096], [279, 1, 177, 67, 1096, 3], [1, 177, 67, 1096, 3, 52], [177, 67, 1096, 3, 52, 6], [67, 1096, 3, 52, 6, 119], [1096, 3, 52, 6, 119, 99], [3, 52, 6, 119, 99, 18], [52, 6, 119, 99, 18, 29], [6, 119, 99, 18, 29, 16], [119, 99, 18, 29, 16, 118]]\n",
      "***********************************\n",
      "La longueur des séquences est :  121832\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"/kaggle/input/pride-prejudice-subtitles-and-text/PP.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()  # Lire le contenu du fichier comme une chaîne de caractères\n",
    "\n",
    "text = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ').replace('“', '').replace('”', '')\n",
    "text = ' '.join(text.split())  # Nettoyage des espaces supplémentaires\n",
    "\n",
    "text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "total_words=len(tokenizer.word_index)\n",
    "total_words\n",
    "tokenizer.word_index\n",
    "sequence_data = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "#Pour enregistrer le tokenizer\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Taille du vocabulaire : {vocab_size}\")\n",
    "\n",
    "sequences = []\n",
    "for i in range(5, len(sequence_data)):\n",
    "    words = sequence_data[i-5:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "print(f\"35 premier sequences: {sequences[:35]}\")\n",
    "print(\"*\"*35)\n",
    "print(\"La longueur des séquences est : \", len(sequences))\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X = sequences[:, :-1]  # Les trois premiers mots\n",
    "y = sequences[:, -1]   # Le mot à prédire\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bd3d1",
   "metadata": {
    "papermill": {
     "duration": 0.006702,
     "end_time": "2024-09-05T17:47:52.439420",
     "exception": false,
     "start_time": "2024-09-05T17:47:52.432718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19157c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:52.454298Z",
     "iopub.status.busy": "2024-09-05T17:47:52.453486Z",
     "iopub.status.idle": "2024-09-05T17:47:57.104785Z",
     "shell.execute_reply": "2024-09-05T17:47:57.103726Z"
    },
    "papermill": {
     "duration": 4.662167,
     "end_time": "2024-09-05T17:47:57.107651",
     "exception": false,
     "start_time": "2024-09-05T17:47:52.445484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f804b",
   "metadata": {
    "papermill": {
     "duration": 0.004364,
     "end_time": "2024-09-05T17:47:57.117228",
     "exception": false,
     "start_time": "2024-09-05T17:47:57.112864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1d6ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:57.128050Z",
     "iopub.status.busy": "2024-09-05T17:47:57.127181Z",
     "iopub.status.idle": "2024-09-05T17:47:58.659970Z",
     "shell.execute_reply": "2024-09-05T17:47:58.659203Z"
    },
    "papermill": {
     "duration": 1.540569,
     "end_time": "2024-09-05T17:47:58.662274",
     "exception": false,
     "start_time": "2024-09-05T17:47:57.121705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 30))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.build(input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c350164f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:58.673722Z",
     "iopub.status.busy": "2024-09-05T17:47:58.672994Z",
     "iopub.status.idle": "2024-09-05T17:47:58.685479Z",
     "shell.execute_reply": "2024-09-05T17:47:58.684627Z"
    },
    "papermill": {
     "duration": 0.019901,
     "end_time": "2024-09-05T17:47:58.687348",
     "exception": false,
     "start_time": "2024-09-05T17:47:58.667447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1336906a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:58.697794Z",
     "iopub.status.busy": "2024-09-05T17:47:58.697520Z",
     "iopub.status.idle": "2024-09-05T17:47:58.716448Z",
     "shell.execute_reply": "2024-09-05T17:47:58.715573Z"
    },
    "papermill": {
     "duration": 0.026398,
     "end_time": "2024-09-05T17:47:58.718327",
     "exception": false,
     "start_time": "2024-09-05T17:47:58.691929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">208,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">689,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6956</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,789,356</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │       \u001b[38;5;34m208,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m400\u001b[0m)         │       \u001b[38;5;34m689,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │     \u001b[38;5;34m1,281,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6956\u001b[0m)           │     \u001b[38;5;34m2,789,356\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,969,236</span> (18.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,969,236\u001b[0m (18.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,969,236</span> (18.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,969,236\u001b[0m (18.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04538d",
   "metadata": {
    "papermill": {
     "duration": 0.005045,
     "end_time": "2024-09-05T17:47:58.728784",
     "exception": false,
     "start_time": "2024-09-05T17:47:58.723739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870cae56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:58.740589Z",
     "iopub.status.busy": "2024-09-05T17:47:58.740053Z",
     "iopub.status.idle": "2024-09-05T17:47:58.744713Z",
     "shell.execute_reply": "2024-09-05T17:47:58.743898Z"
    },
    "papermill": {
     "duration": 0.012573,
     "end_time": "2024-09-05T17:47:58.746596",
     "exception": false,
     "start_time": "2024-09-05T17:47:58.734023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"/tmp/next_words.keras\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa15ccc",
   "metadata": {
    "papermill": {
     "duration": 0.005007,
     "end_time": "2024-09-05T17:47:58.757107",
     "exception": false,
     "start_time": "2024-09-05T17:47:58.752100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb59bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T17:47:58.769020Z",
     "iopub.status.busy": "2024-09-05T17:47:58.768357Z",
     "iopub.status.idle": "2024-09-05T18:11:00.628351Z",
     "shell.execute_reply": "2024-09-05T18:11:00.627535Z"
    },
    "papermill": {
     "duration": 1381.868418,
     "end_time": "2024-09-05T18:11:00.630737",
     "exception": false,
     "start_time": "2024-09-05T17:47:58.762319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6088\n",
      "Epoch 1: val_loss improved from inf to 6.01198, saving model to /tmp/next_words.keras\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 6.6080 - val_loss: 6.0120\n",
      "Epoch 2/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7682\n",
      "Epoch 2: val_loss improved from 6.01198 to 5.63699, saving model to /tmp/next_words.keras\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 5.7677 - val_loss: 5.6370\n",
      "Epoch 3/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2852\n",
      "Epoch 3: val_loss improved from 5.63699 to 5.52424, saving model to /tmp/next_words.keras\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 5.2852 - val_loss: 5.5242\n",
      "Epoch 4/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9404\n",
      "Epoch 4: val_loss improved from 5.52424 to 5.48332, saving model to /tmp/next_words.keras\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 4.9404 - val_loss: 5.4833\n",
      "Epoch 5/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6230\n",
      "Epoch 5: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 4.6232 - val_loss: 5.5244\n",
      "Epoch 6/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3075\n",
      "Epoch 6: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 4.3075 - val_loss: 5.6165\n",
      "Epoch 7/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9600\n",
      "Epoch 7: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 3.9601 - val_loss: 5.7314\n",
      "Epoch 8/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6150\n",
      "Epoch 8: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 3.6151 - val_loss: 5.8924\n",
      "Epoch 9/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2747\n",
      "Epoch 9: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 3.2751 - val_loss: 6.0412\n",
      "Epoch 10/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9262\n",
      "Epoch 10: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 2.9266 - val_loss: 6.1968\n",
      "Epoch 11/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6003\n",
      "Epoch 11: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 2.6005 - val_loss: 6.3838\n",
      "Epoch 12/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2774\n",
      "Epoch 12: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 2.2775 - val_loss: 6.5731\n",
      "Epoch 13/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9526\n",
      "Epoch 13: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 1.9530 - val_loss: 6.7594\n",
      "Epoch 14/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6556\n",
      "Epoch 14: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 1.6560 - val_loss: 7.0138\n",
      "Epoch 15/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3706\n",
      "Epoch 15: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 1.3709 - val_loss: 7.2153\n",
      "Epoch 16/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1054\n",
      "Epoch 16: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 1.1056 - val_loss: 7.4508\n",
      "Epoch 17/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8555\n",
      "Epoch 17: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.8557 - val_loss: 7.7092\n",
      "Epoch 18/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6562\n",
      "Epoch 18: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.6563 - val_loss: 7.9537\n",
      "Epoch 19/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4898\n",
      "Epoch 19: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.4898 - val_loss: 8.2531\n",
      "Epoch 20/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3572\n",
      "Epoch 20: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3575 - val_loss: 8.4972\n",
      "Epoch 21/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2670\n",
      "Epoch 21: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2672 - val_loss: 8.7534\n",
      "Epoch 22/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2059\n",
      "Epoch 22: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.2059 - val_loss: 8.9958\n",
      "Epoch 23/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1623\n",
      "Epoch 23: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1625 - val_loss: 9.2159\n",
      "Epoch 24/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1425\n",
      "Epoch 24: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1426 - val_loss: 9.4785\n",
      "Epoch 25/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1218\n",
      "Epoch 25: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.1219 - val_loss: 9.5776\n",
      "Epoch 26/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1206\n",
      "Epoch 26: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.1207 - val_loss: 9.8090\n",
      "Epoch 27/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1006\n",
      "Epoch 27: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.1006 - val_loss: 9.9397\n",
      "Epoch 28/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1018\n",
      "Epoch 28: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.1019 - val_loss: 10.0757\n",
      "Epoch 29/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0996\n",
      "Epoch 29: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0996 - val_loss: 10.2211\n",
      "Epoch 30/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0918\n",
      "Epoch 30: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0918 - val_loss: 10.3492\n",
      "Epoch 31/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0911\n",
      "Epoch 31: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0911 - val_loss: 10.4365\n",
      "Epoch 32/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0865\n",
      "Epoch 32: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0865 - val_loss: 10.5837\n",
      "Epoch 33/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0902\n",
      "Epoch 33: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0902 - val_loss: 10.6796\n",
      "Epoch 34/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0808\n",
      "Epoch 34: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0808 - val_loss: 10.7444\n",
      "Epoch 35/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0803\n",
      "Epoch 35: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0803 - val_loss: 10.8553\n",
      "Epoch 36/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0811\n",
      "Epoch 36: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 10.9191\n",
      "Epoch 37/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0780\n",
      "Epoch 37: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0781 - val_loss: 11.0393\n",
      "Epoch 38/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0809\n",
      "Epoch 38: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0810 - val_loss: 11.0865\n",
      "Epoch 39/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0773\n",
      "Epoch 39: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0773 - val_loss: 11.1872\n",
      "Epoch 40/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0701\n",
      "Epoch 40: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0702 - val_loss: 11.2448\n",
      "Epoch 41/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0842\n",
      "Epoch 41: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0843 - val_loss: 11.2741\n",
      "Epoch 42/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0831\n",
      "Epoch 42: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0831 - val_loss: 11.3761\n",
      "Epoch 43/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0634\n",
      "Epoch 43: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0635 - val_loss: 11.3915\n",
      "Epoch 44/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0830\n",
      "Epoch 44: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0830 - val_loss: 11.4794\n",
      "Epoch 45/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0736\n",
      "Epoch 45: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0737 - val_loss: 11.5466\n",
      "Epoch 46/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0776\n",
      "Epoch 46: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 11.6151\n",
      "Epoch 47/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0692\n",
      "Epoch 47: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0692 - val_loss: 11.6267\n",
      "Epoch 48/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0782\n",
      "Epoch 48: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0782 - val_loss: 11.7111\n",
      "Epoch 49/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0667\n",
      "Epoch 49: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0667 - val_loss: 11.7726\n",
      "Epoch 50/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0728\n",
      "Epoch 50: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0728 - val_loss: 11.8342\n",
      "Epoch 51/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0687\n",
      "Epoch 51: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0687 - val_loss: 11.8862\n",
      "Epoch 52/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0736\n",
      "Epoch 52: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0736 - val_loss: 11.9368\n",
      "Epoch 53/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0703\n",
      "Epoch 53: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0703 - val_loss: 11.9497\n",
      "Epoch 54/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0657\n",
      "Epoch 54: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0658 - val_loss: 12.0163\n",
      "Epoch 55/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0681\n",
      "Epoch 55: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0682 - val_loss: 12.0296\n",
      "Epoch 56/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0770\n",
      "Epoch 56: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0770 - val_loss: 12.0805\n",
      "Epoch 57/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0742\n",
      "Epoch 57: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0742 - val_loss: 12.1259\n",
      "Epoch 58/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0688\n",
      "Epoch 58: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0689 - val_loss: 12.2160\n",
      "Epoch 59/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0717\n",
      "Epoch 59: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0717 - val_loss: 12.2711\n",
      "Epoch 60/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0733\n",
      "Epoch 60: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0733 - val_loss: 12.2695\n",
      "Epoch 61/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0649\n",
      "Epoch 61: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0650 - val_loss: 12.2985\n",
      "Epoch 62/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0698\n",
      "Epoch 62: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0698 - val_loss: 12.3598\n",
      "Epoch 63/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0674\n",
      "Epoch 63: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0674 - val_loss: 12.3804\n",
      "Epoch 64/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0760\n",
      "Epoch 64: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0761 - val_loss: 12.4448\n",
      "Epoch 65/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0765\n",
      "Epoch 65: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0765 - val_loss: 12.4343\n",
      "Epoch 66/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0659\n",
      "Epoch 66: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0660 - val_loss: 12.5142\n",
      "Epoch 67/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0652\n",
      "Epoch 67: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0652 - val_loss: 12.5591\n",
      "Epoch 68/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0777\n",
      "Epoch 68: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0777 - val_loss: 12.5805\n",
      "Epoch 69/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0623\n",
      "Epoch 69: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0623 - val_loss: 12.5616\n",
      "Epoch 70/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0795\n",
      "Epoch 70: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0795 - val_loss: 12.6265\n",
      "Epoch 71/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0712\n",
      "Epoch 71: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0713 - val_loss: 12.6731\n",
      "Epoch 72/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0704\n",
      "Epoch 72: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0704 - val_loss: 12.6737\n",
      "Epoch 73/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0719\n",
      "Epoch 73: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0719 - val_loss: 12.6858\n",
      "Epoch 74/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0677\n",
      "Epoch 74: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0677 - val_loss: 12.7522\n",
      "Epoch 75/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0720\n",
      "Epoch 75: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0720 - val_loss: 12.7803\n",
      "Epoch 76/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0696\n",
      "Epoch 76: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0696 - val_loss: 12.8823\n",
      "Epoch 77/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0691\n",
      "Epoch 77: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0691 - val_loss: 12.8659\n",
      "Epoch 78/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0627\n",
      "Epoch 78: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0628 - val_loss: 12.8989\n",
      "Epoch 79/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0725\n",
      "Epoch 79: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0726 - val_loss: 12.9067\n",
      "Epoch 80/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680\n",
      "Epoch 80: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0681 - val_loss: 12.9333\n",
      "Epoch 81/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0735\n",
      "Epoch 81: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0735 - val_loss: 12.9332\n",
      "Epoch 82/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0613\n",
      "Epoch 82: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0614 - val_loss: 13.0359\n",
      "Epoch 83/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0723\n",
      "Epoch 83: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0723 - val_loss: 13.0416\n",
      "Epoch 84/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680\n",
      "Epoch 84: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0680 - val_loss: 13.0396\n",
      "Epoch 85/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0697\n",
      "Epoch 85: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0697 - val_loss: 13.0604\n",
      "Epoch 86/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0704\n",
      "Epoch 86: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0704 - val_loss: 13.1089\n",
      "Epoch 87/500\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0671\n",
      "Epoch 87: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0671 - val_loss: 13.1606\n",
      "Epoch 88/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0702\n",
      "Epoch 88: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 0.0702 - val_loss: 13.1199\n",
      "Epoch 89/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0705\n",
      "Epoch 89: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0705 - val_loss: 13.1474\n",
      "Epoch 90/500\n",
      "\u001b[1m1517/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0674\n",
      "Epoch 90: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0674 - val_loss: 13.2133\n",
      "Epoch 91/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0611\n",
      "Epoch 91: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0611 - val_loss: 13.2045\n",
      "Epoch 92/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0726\n",
      "Epoch 92: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0727 - val_loss: 13.2907\n",
      "Epoch 93/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0703\n",
      "Epoch 93: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0703 - val_loss: 13.2720\n",
      "Epoch 94/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0662\n",
      "Epoch 94: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0662 - val_loss: 13.2451\n",
      "Epoch 95/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0633\n",
      "Epoch 95: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0633 - val_loss: 13.2878\n",
      "Epoch 96/500\n",
      "\u001b[1m1522/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0685\n",
      "Epoch 96: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0685 - val_loss: 13.3321\n",
      "Epoch 97/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0623\n",
      "Epoch 97: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0623 - val_loss: 13.3802\n",
      "Epoch 98/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0710\n",
      "Epoch 98: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0710 - val_loss: 13.4422\n",
      "Epoch 99/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0706\n",
      "Epoch 99: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0707 - val_loss: 13.3874\n",
      "Epoch 100/500\n",
      "\u001b[1m1518/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0651\n",
      "Epoch 100: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0652 - val_loss: 13.4457\n",
      "Epoch 101/500\n",
      "\u001b[1m1520/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0666\n",
      "Epoch 101: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0667 - val_loss: 13.4836\n",
      "Epoch 102/500\n",
      "\u001b[1m1521/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0718\n",
      "Epoch 102: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0718 - val_loss: 13.4888\n",
      "Epoch 103/500\n",
      "\u001b[1m1516/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0702\n",
      "Epoch 103: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0703 - val_loss: 13.5050\n",
      "Epoch 104/500\n",
      "\u001b[1m1519/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680\n",
      "Epoch 104: val_loss did not improve from 5.48332\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0680 - val_loss: 13.5511\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=500,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5b63de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T18:11:04.441059Z",
     "iopub.status.busy": "2024-09-05T18:11:04.440105Z",
     "iopub.status.idle": "2024-09-05T18:11:04.445226Z",
     "shell.execute_reply": "2024-09-05T18:11:04.444207Z"
    },
    "papermill": {
     "duration": 1.939802,
     "end_time": "2024-09-05T18:11:04.447280",
     "exception": false,
     "start_time": "2024-09-05T18:11:02.507478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train,\n",
    "#                     epochs=50,\n",
    "#                     batch_size=64,\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     callbacks=[checkpoint, early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185abb8",
   "metadata": {
    "papermill": {
     "duration": 1.816229,
     "end_time": "2024-09-05T18:11:08.162788",
     "exception": false,
     "start_time": "2024-09-05T18:11:06.346559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c104d",
   "metadata": {
    "papermill": {
     "duration": 1.873707,
     "end_time": "2024-09-05T18:11:11.908031",
     "exception": false,
     "start_time": "2024-09-05T18:11:10.034324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8a59c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T18:11:15.647191Z",
     "iopub.status.busy": "2024-09-05T18:11:15.646334Z",
     "iopub.status.idle": "2024-09-05T18:11:24.642438Z",
     "shell.execute_reply": "2024-09-05T18:11:24.641361Z"
    },
    "papermill": {
     "duration": 10.881324,
     "end_time": "2024-09-05T18:11:24.644557",
     "exception": false,
     "start_time": "2024-09-05T18:11:13.763233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Texte généré: this night was not a great deal of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of the world and the rest of\n"
     ]
    }
   ],
   "source": [
    "### Generation d'une texte a l'aide d'une phrase saisit par utilsiateur\n",
    "initial_text = \"this night\"\n",
    "num_words_to_generate = 150\n",
    "\n",
    "for _ in range(num_words_to_generate):\n",
    "    # Convertir le texte actuel en séquence d'indices\n",
    "    sequence = tokenizer.texts_to_sequences([initial_text])[0]\n",
    "    sequence = np.array(sequence[-5:]).reshape(1, -1)  \n",
    "\n",
    "    # Prédire le prochain mot\n",
    "    predicted_probabilities = model.predict(sequence)\n",
    "    predicted_index = np.argmax(predicted_probabilities)\n",
    "    predicted_word = tokenizer.index_word.get(predicted_index, '')\n",
    "\n",
    "    initial_text += ' ' + predicted_word\n",
    "\n",
    "print(\"Texte généré:\", initial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15aedd",
   "metadata": {
    "papermill": {
     "duration": 1.936952,
     "end_time": "2024-09-05T18:11:28.476374",
     "exception": false,
     "start_time": "2024-09-05T18:11:26.539422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1357760,
     "sourceId": 2256379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1437.268535,
   "end_time": "2024-09-05T18:11:33.146728",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-05T17:47:35.878193",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
