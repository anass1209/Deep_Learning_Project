{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afed053b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-07T17:51:24.008831Z",
     "iopub.status.busy": "2024-09-07T17:51:24.008463Z",
     "iopub.status.idle": "2024-09-07T17:51:37.562518Z",
     "shell.execute_reply": "2024-09-07T17:51:37.561577Z"
    },
    "papermill": {
     "duration": 13.560581,
     "end_time": "2024-09-07T17:51:37.564753",
     "exception": false,
     "start_time": "2024-09-07T17:51:24.004172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 6745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"/kaggle/input/pride-prejudice-subtitles-and-text/PP.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "text = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ').replace('“', '').replace('”', '')\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "with open('token.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Taille du vocabulaire : {vocab_size}\")\n",
    "\n",
    "text = text[:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aa2862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T17:51:37.571838Z",
     "iopub.status.busy": "2024-09-07T17:51:37.571258Z",
     "iopub.status.idle": "2024-09-07T17:51:37.620976Z",
     "shell.execute_reply": "2024-09-07T17:51:37.620294Z"
    },
    "papermill": {
     "duration": 0.055083,
     "end_time": "2024-09-07T17:51:37.622865",
     "exception": false,
     "start_time": "2024-09-07T17:51:37.567782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_data = tokenizer.texts_to_sequences([text])[0]\n",
    "sequences = []\n",
    "for i in range(5, len(sequence_data)):\n",
    "    words = sequence_data[i-5:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4088e",
   "metadata": {
    "papermill": {
     "duration": 0.00233,
     "end_time": "2024-09-07T17:51:37.627735",
     "exception": false,
     "start_time": "2024-09-07T17:51:37.625405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2a6c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T17:51:37.633837Z",
     "iopub.status.busy": "2024-09-07T17:51:37.633533Z",
     "iopub.status.idle": "2024-09-07T17:51:37.680484Z",
     "shell.execute_reply": "2024-09-07T17:51:37.679696Z"
    },
    "papermill": {
     "duration": 0.052525,
     "end_time": "2024-09-07T17:51:37.682719",
     "exception": false,
     "start_time": "2024-09-07T17:51:37.630194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diviser les données en entrée et sortie\n",
    "X = sequences[:, :-1]  \n",
    "y = sequences[:, -1]  \n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f0cfa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T17:51:37.689579Z",
     "iopub.status.busy": "2024-09-07T17:51:37.689229Z",
     "iopub.status.idle": "2024-09-07T17:51:38.378344Z",
     "shell.execute_reply": "2024-09-07T17:51:38.377572Z"
    },
    "papermill": {
     "duration": 0.695082,
     "end_time": "2024-09-07T17:51:38.380688",
     "exception": false,
     "start_time": "2024-09-07T17:51:37.685606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 40))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(GRU(120)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a24aee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T17:51:38.391637Z",
     "iopub.status.busy": "2024-09-07T17:51:38.391278Z",
     "iopub.status.idle": "2024-09-07T17:59:13.983136Z",
     "shell.execute_reply": "2024-09-07T17:59:13.982214Z"
    },
    "papermill": {
     "duration": 455.599282,
     "end_time": "2024-09-07T17:59:13.985069",
     "exception": false,
     "start_time": "2024-09-07T17:51:38.385787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0315 - loss: 7.0830\n",
      "Epoch 2/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0432 - loss: 6.0764\n",
      "Epoch 3/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0659 - loss: 5.8115\n",
      "Epoch 4/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0818 - loss: 5.5884\n",
      "Epoch 5/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0948 - loss: 5.3508\n",
      "Epoch 6/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1078 - loss: 5.1344\n",
      "Epoch 7/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1226 - loss: 4.9367\n",
      "Epoch 8/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1327 - loss: 4.7347\n",
      "Epoch 9/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1362 - loss: 4.5656\n",
      "Epoch 10/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1558 - loss: 4.3572\n",
      "Epoch 11/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1739 - loss: 4.1516\n",
      "Epoch 12/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1858 - loss: 3.9891\n",
      "Epoch 13/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2081 - loss: 3.8049\n",
      "Epoch 14/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2390 - loss: 3.5887\n",
      "Epoch 15/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2590 - loss: 3.4308\n",
      "Epoch 16/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2815 - loss: 3.2668\n",
      "Epoch 17/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3044 - loss: 3.1369\n",
      "Epoch 18/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3228 - loss: 3.0067\n",
      "Epoch 19/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3487 - loss: 2.8671\n",
      "Epoch 20/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3664 - loss: 2.7510\n",
      "Epoch 21/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3855 - loss: 2.6528\n",
      "Epoch 22/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3932 - loss: 2.5918\n",
      "Epoch 23/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4260 - loss: 2.4574\n",
      "Epoch 24/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4335 - loss: 2.3893\n",
      "Epoch 25/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4504 - loss: 2.3005\n",
      "Epoch 26/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4640 - loss: 2.2377\n",
      "Epoch 27/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4748 - loss: 2.1605\n",
      "Epoch 28/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4828 - loss: 2.1152\n",
      "Epoch 29/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4891 - loss: 2.0791\n",
      "Epoch 30/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5061 - loss: 2.0139\n",
      "Epoch 31/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5121 - loss: 1.9444\n",
      "Epoch 32/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5244 - loss: 1.8971\n",
      "Epoch 33/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5366 - loss: 1.8553\n",
      "Epoch 34/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5488 - loss: 1.7916\n",
      "Epoch 35/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5456 - loss: 1.7792\n",
      "Epoch 36/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5575 - loss: 1.7439\n",
      "Epoch 37/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5628 - loss: 1.6865\n",
      "Epoch 38/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5710 - loss: 1.6805\n",
      "Epoch 39/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5712 - loss: 1.6380\n",
      "Epoch 40/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5866 - loss: 1.5961\n",
      "Epoch 41/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5814 - loss: 1.5993\n",
      "Epoch 42/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5991 - loss: 1.5462\n",
      "Epoch 43/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5986 - loss: 1.5184\n",
      "Epoch 44/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5978 - loss: 1.5319\n",
      "Epoch 45/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6170 - loss: 1.4541\n",
      "Epoch 46/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6160 - loss: 1.4411\n",
      "Epoch 47/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6183 - loss: 1.4405\n",
      "Epoch 48/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6294 - loss: 1.4040\n",
      "Epoch 49/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6284 - loss: 1.3861\n",
      "Epoch 50/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6242 - loss: 1.3917\n",
      "Epoch 51/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6407 - loss: 1.3628\n",
      "Epoch 52/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6331 - loss: 1.3570\n",
      "Epoch 53/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6404 - loss: 1.3048\n",
      "Epoch 54/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6553 - loss: 1.3017\n",
      "Epoch 55/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6558 - loss: 1.2863\n",
      "Epoch 56/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6555 - loss: 1.2768\n",
      "Epoch 57/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6597 - loss: 1.2540\n",
      "Epoch 58/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6592 - loss: 1.2603\n",
      "Epoch 59/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6552 - loss: 1.2354\n",
      "Epoch 60/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6725 - loss: 1.1985\n",
      "Epoch 61/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6666 - loss: 1.2125\n",
      "Epoch 62/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6771 - loss: 1.1806\n",
      "Epoch 63/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6831 - loss: 1.1722\n",
      "Epoch 64/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6747 - loss: 1.1642\n",
      "Epoch 65/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6886 - loss: 1.1364\n",
      "Epoch 66/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6805 - loss: 1.1568\n",
      "Epoch 67/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6871 - loss: 1.1404\n",
      "Epoch 68/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6909 - loss: 1.1225\n",
      "Epoch 69/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6911 - loss: 1.1306\n",
      "Epoch 70/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6845 - loss: 1.1317\n",
      "Epoch 71/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7023 - loss: 1.0754\n",
      "Epoch 72/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7074 - loss: 1.0679\n",
      "Epoch 73/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6981 - loss: 1.0722\n",
      "Epoch 74/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6951 - loss: 1.0720\n",
      "Epoch 75/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6992 - loss: 1.0606\n",
      "Epoch 76/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6940 - loss: 1.0846\n",
      "Epoch 77/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7059 - loss: 1.0663\n",
      "Epoch 78/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7128 - loss: 1.0152\n",
      "Epoch 79/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7095 - loss: 1.0592\n",
      "Epoch 80/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7035 - loss: 1.0373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ea978ab6b30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=80, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cc8567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T17:59:15.291391Z",
     "iopub.status.busy": "2024-09-07T17:59:15.290993Z",
     "iopub.status.idle": "2024-09-07T17:59:17.895317Z",
     "shell.execute_reply": "2024-09-07T17:59:17.894136Z"
    },
    "papermill": {
     "duration": 3.258308,
     "end_time": "2024-09-07T17:59:17.897300",
     "exception": false,
     "start_time": "2024-09-07T17:59:14.638992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have a bad financial astonishment and the party was not joined in a day in the country but you must acknowledge to be true certainly my dear nobody said there were but as to be meeting with many fortune eyes in the room he was lively and unreserved danced\n"
     ]
    }
   ],
   "source": [
    "input_text = \"you have a bad financial\"\n",
    "predict_next_words = 45\n",
    "\n",
    "\n",
    "for _ in range(predict_next_words):\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    \n",
    "    input_sequence = input_sequence[-5:]\n",
    "    \n",
    "    input_sequence = np.array(input_sequence).reshape(1, -1)\n",
    "    \n",
    "    predicted_prob = model.predict(input_sequence, verbose=0)\n",
    "    predicted_index = np.argmax(predicted_prob, axis=-1)\n",
    "    \n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    if output_word == \"\":\n",
    "        print(\"Aucun mot prédit trouvé.\")\n",
    "        break\n",
    "    \n",
    "    input_text += \" \" + output_word\n",
    "\n",
    "print(input_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1357760,
     "sourceId": 2256379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 479.930121,
   "end_time": "2024-09-07T17:59:21.281243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-07T17:51:21.351122",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
