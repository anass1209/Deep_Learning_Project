{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c557e56e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-07T16:10:57.192888Z",
     "iopub.status.busy": "2024-09-07T16:10:57.192105Z",
     "iopub.status.idle": "2024-09-07T16:11:11.800249Z",
     "shell.execute_reply": "2024-09-07T16:11:11.798926Z"
    },
    "papermill": {
     "duration": 14.615314,
     "end_time": "2024-09-07T16:11:11.802486",
     "exception": false,
     "start_time": "2024-09-07T16:10:57.187172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 6745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"/kaggle/input/pride-prejudice-subtitles-and-text/PP.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "text = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ').replace('“', '').replace('”', '')\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "with open('token.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Taille du vocabulaire : {vocab_size}\")\n",
    "\n",
    "text = text[:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e86df6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:11:11.810121Z",
     "iopub.status.busy": "2024-09-07T16:11:11.809072Z",
     "iopub.status.idle": "2024-09-07T16:11:11.859124Z",
     "shell.execute_reply": "2024-09-07T16:11:11.858165Z"
    },
    "papermill": {
     "duration": 0.055678,
     "end_time": "2024-09-07T16:11:11.861160",
     "exception": false,
     "start_time": "2024-09-07T16:11:11.805482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_data = tokenizer.texts_to_sequences([text])[0]\n",
    "sequences = []\n",
    "for i in range(5, len(sequence_data)):\n",
    "    words = sequence_data[i-5:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8c74e",
   "metadata": {
    "papermill": {
     "duration": 0.00241,
     "end_time": "2024-09-07T16:11:11.866371",
     "exception": false,
     "start_time": "2024-09-07T16:11:11.863961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6518e5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:11:11.872907Z",
     "iopub.status.busy": "2024-09-07T16:11:11.872335Z",
     "iopub.status.idle": "2024-09-07T16:11:11.919876Z",
     "shell.execute_reply": "2024-09-07T16:11:11.919099Z"
    },
    "papermill": {
     "duration": 0.053591,
     "end_time": "2024-09-07T16:11:11.922475",
     "exception": false,
     "start_time": "2024-09-07T16:11:11.868884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diviser les données en entrée et sortie\n",
    "X = sequences[:, :-1]  \n",
    "y = sequences[:, -1]  \n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac8c2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:11:11.929648Z",
     "iopub.status.busy": "2024-09-07T16:11:11.929058Z",
     "iopub.status.idle": "2024-09-07T16:11:13.178649Z",
     "shell.execute_reply": "2024-09-07T16:11:13.177852Z"
    },
    "papermill": {
     "duration": 1.255583,
     "end_time": "2024-09-07T16:11:13.180949",
     "exception": false,
     "start_time": "2024-09-07T16:11:11.925366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50))\n",
    "model.add(Bidirectional(GRU(120)))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.build(input_shape=(None, X.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2da6f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:11:13.188104Z",
     "iopub.status.busy": "2024-09-07T16:11:13.187561Z",
     "iopub.status.idle": "2024-09-07T16:18:38.643839Z",
     "shell.execute_reply": "2024-09-07T16:18:38.642866Z"
    },
    "papermill": {
     "duration": 445.462043,
     "end_time": "2024-09-07T16:18:38.645968",
     "exception": false,
     "start_time": "2024-09-07T16:11:13.183925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.0310 - loss: 7.0738\n",
      "Epoch 2/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0564 - loss: 5.9692\n",
      "Epoch 3/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.0800 - loss: 5.5707\n",
      "Epoch 4/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.1056 - loss: 5.1886\n",
      "Epoch 5/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.1266 - loss: 4.8142\n",
      "Epoch 6/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.1517 - loss: 4.4634\n",
      "Epoch 7/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.1775 - loss: 4.0800\n",
      "Epoch 8/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2216 - loss: 3.7026\n",
      "Epoch 9/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2839 - loss: 3.3204\n",
      "Epoch 10/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3480 - loss: 2.9291\n",
      "Epoch 11/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4166 - loss: 2.5980\n",
      "Epoch 12/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4768 - loss: 2.3043\n",
      "Epoch 13/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5451 - loss: 2.0143\n",
      "Epoch 14/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6036 - loss: 1.7515\n",
      "Epoch 15/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6580 - loss: 1.5291\n",
      "Epoch 16/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7036 - loss: 1.3269\n",
      "Epoch 17/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7612 - loss: 1.1122\n",
      "Epoch 18/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8056 - loss: 0.9345\n",
      "Epoch 19/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8431 - loss: 0.7831\n",
      "Epoch 20/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8786 - loss: 0.6444\n",
      "Epoch 21/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9092 - loss: 0.5222\n",
      "Epoch 22/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9409 - loss: 0.4022\n",
      "Epoch 23/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9607 - loss: 0.3153\n",
      "Epoch 24/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9713 - loss: 0.2470\n",
      "Epoch 25/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9841 - loss: 0.1790\n",
      "Epoch 26/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.1347\n",
      "Epoch 27/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9952 - loss: 0.1001\n",
      "Epoch 28/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0737\n",
      "Epoch 29/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0560\n",
      "Epoch 30/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0455\n",
      "Epoch 31/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0359\n",
      "Epoch 32/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0336\n",
      "Epoch 33/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9952 - loss: 0.0479\n",
      "Epoch 34/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9971 - loss: 0.0373\n",
      "Epoch 35/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0242\n",
      "Epoch 36/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0227\n",
      "Epoch 37/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0175\n",
      "Epoch 38/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0180\n",
      "Epoch 39/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0951\n",
      "Epoch 40/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9956 - loss: 0.0345\n",
      "Epoch 41/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0121\n",
      "Epoch 42/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0120\n",
      "Epoch 43/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0108\n",
      "Epoch 44/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0105\n",
      "Epoch 45/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0140\n",
      "Epoch 46/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0121\n",
      "Epoch 47/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9961 - loss: 0.0240\n",
      "Epoch 48/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9764 - loss: 0.0989\n",
      "Epoch 49/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9956 - loss: 0.0278\n",
      "Epoch 50/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9973 - loss: 0.0144\n",
      "Epoch 51/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0082\n",
      "Epoch 52/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0116\n",
      "Epoch 53/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0085\n",
      "Epoch 54/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0151\n",
      "Epoch 55/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.0167\n",
      "Epoch 56/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9960 - loss: 0.0231\n",
      "Epoch 57/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0586\n",
      "Epoch 58/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9965 - loss: 0.0231\n",
      "Epoch 59/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0092\n",
      "Epoch 60/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0092\n",
      "Epoch 61/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0086\n",
      "Epoch 62/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0083\n",
      "Epoch 63/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0115\n",
      "Epoch 64/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0102\n",
      "Epoch 65/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0512\n",
      "Epoch 66/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0443\n",
      "Epoch 67/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0133\n",
      "Epoch 68/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0078\n",
      "Epoch 69/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0108\n",
      "Epoch 70/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0094\n",
      "Epoch 71/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0085\n",
      "Epoch 72/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0108\n",
      "Epoch 73/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0105\n",
      "Epoch 74/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0107\n",
      "Epoch 75/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9704 - loss: 0.1134\n",
      "Epoch 76/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0257\n",
      "Epoch 77/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0090\n",
      "Epoch 78/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0074\n",
      "Epoch 79/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0066\n",
      "Epoch 80/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7aaae0330e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=80, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92b1a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:18:39.942682Z",
     "iopub.status.busy": "2024-09-07T16:18:39.942290Z",
     "iopub.status.idle": "2024-09-07T16:18:42.681069Z",
     "shell.execute_reply": "2024-09-07T16:18:42.679943Z"
    },
    "papermill": {
     "duration": 3.392149,
     "end_time": "2024-09-07T16:18:42.683829",
     "exception": false,
     "start_time": "2024-09-07T16:18:39.291680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife however little known the feelings or views of such a man may be on his first entering a neighbourhood this truth is so well fixed in the\n"
     ]
    }
   ],
   "source": [
    "input_text = \" It is a truth universally\"\n",
    "predict_next_words = 45\n",
    "\n",
    "\n",
    "for _ in range(predict_next_words):\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    \n",
    "    input_sequence = input_sequence[-5:]\n",
    "    \n",
    "    input_sequence = np.array(input_sequence).reshape(1, -1)\n",
    "    \n",
    "    predicted_prob = model.predict(input_sequence, verbose=0)\n",
    "    predicted_index = np.argmax(predicted_prob, axis=-1)\n",
    "    \n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    if output_word == \"\":\n",
    "        print(\"Aucun mot prédit trouvé.\")\n",
    "        break\n",
    "    \n",
    "    input_text += \" \" + output_word\n",
    "\n",
    "print(input_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1357760,
     "sourceId": 2256379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 471.97881,
   "end_time": "2024-09-07T16:18:46.381613",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-07T16:10:54.402803",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
