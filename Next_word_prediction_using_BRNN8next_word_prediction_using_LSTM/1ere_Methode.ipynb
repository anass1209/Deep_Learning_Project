{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f148625b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-07T16:27:19.606213Z",
     "iopub.status.busy": "2024-09-07T16:27:19.605755Z",
     "iopub.status.idle": "2024-09-07T16:27:33.224731Z",
     "shell.execute_reply": "2024-09-07T16:27:33.223252Z"
    },
    "papermill": {
     "duration": 13.625613,
     "end_time": "2024-09-07T16:27:33.226864",
     "exception": false,
     "start_time": "2024-09-07T16:27:19.601251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 6745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"/kaggle/input/pride-prejudice-subtitles-and-text/PP.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "text = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ').replace('“', '').replace('”', '')\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "with open('token.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Taille du vocabulaire : {vocab_size}\")\n",
    "\n",
    "text = text[:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f288e9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:27:33.233799Z",
     "iopub.status.busy": "2024-09-07T16:27:33.233248Z",
     "iopub.status.idle": "2024-09-07T16:27:33.282047Z",
     "shell.execute_reply": "2024-09-07T16:27:33.281318Z"
    },
    "papermill": {
     "duration": 0.054285,
     "end_time": "2024-09-07T16:27:33.284100",
     "exception": false,
     "start_time": "2024-09-07T16:27:33.229815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_data = tokenizer.texts_to_sequences([text])[0]\n",
    "sequences = []\n",
    "for i in range(5, len(sequence_data)):\n",
    "    words = sequence_data[i-5:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fc02a",
   "metadata": {
    "papermill": {
     "duration": 0.00239,
     "end_time": "2024-09-07T16:27:33.289413",
     "exception": false,
     "start_time": "2024-09-07T16:27:33.287023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c116ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:27:33.295555Z",
     "iopub.status.busy": "2024-09-07T16:27:33.295245Z",
     "iopub.status.idle": "2024-09-07T16:27:33.343057Z",
     "shell.execute_reply": "2024-09-07T16:27:33.342055Z"
    },
    "papermill": {
     "duration": 0.053585,
     "end_time": "2024-09-07T16:27:33.345437",
     "exception": false,
     "start_time": "2024-09-07T16:27:33.291852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diviser les données en entrée et sortie\n",
    "X = sequences[:, :-1]  \n",
    "y = sequences[:, -1]  \n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6368b84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:27:33.352229Z",
     "iopub.status.busy": "2024-09-07T16:27:33.351878Z",
     "iopub.status.idle": "2024-09-07T16:27:34.596856Z",
     "shell.execute_reply": "2024-09-07T16:27:34.595853Z"
    },
    "papermill": {
     "duration": 1.251365,
     "end_time": "2024-09-07T16:27:34.599694",
     "exception": false,
     "start_time": "2024-09-07T16:27:33.348329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50))\n",
    "model.add(Bidirectional(GRU(120)))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.build(input_shape=(None, X.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55250613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:27:34.609040Z",
     "iopub.status.busy": "2024-09-07T16:27:34.608409Z",
     "iopub.status.idle": "2024-09-07T16:35:03.923576Z",
     "shell.execute_reply": "2024-09-07T16:35:03.922615Z"
    },
    "papermill": {
     "duration": 449.322511,
     "end_time": "2024-09-07T16:35:03.926227",
     "exception": false,
     "start_time": "2024-09-07T16:27:34.603716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.0280 - loss: 7.0776\n",
      "Epoch 2/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.0453 - loss: 5.9844\n",
      "Epoch 3/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.0763 - loss: 5.6634\n",
      "Epoch 4/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.1058 - loss: 5.2418\n",
      "Epoch 5/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1289 - loss: 4.8683\n",
      "Epoch 6/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1449 - loss: 4.5001\n",
      "Epoch 7/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1793 - loss: 4.1290\n",
      "Epoch 8/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2190 - loss: 3.7232\n",
      "Epoch 9/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2836 - loss: 3.2935\n",
      "Epoch 10/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3526 - loss: 2.9027\n",
      "Epoch 11/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4298 - loss: 2.5376\n",
      "Epoch 12/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4958 - loss: 2.2313\n",
      "Epoch 13/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5487 - loss: 1.9556\n",
      "Epoch 14/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6198 - loss: 1.6918\n",
      "Epoch 15/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6735 - loss: 1.4659\n",
      "Epoch 16/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7215 - loss: 1.2622\n",
      "Epoch 17/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7711 - loss: 1.0675\n",
      "Epoch 18/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8191 - loss: 0.8905\n",
      "Epoch 19/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8539 - loss: 0.7540\n",
      "Epoch 20/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8950 - loss: 0.5951\n",
      "Epoch 21/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9206 - loss: 0.4892\n",
      "Epoch 22/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9423 - loss: 0.3860\n",
      "Epoch 23/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9612 - loss: 0.2967\n",
      "Epoch 24/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9773 - loss: 0.2233\n",
      "Epoch 25/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.1683\n",
      "Epoch 26/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9921 - loss: 0.1267\n",
      "Epoch 27/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9948 - loss: 0.0955\n",
      "Epoch 28/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9973 - loss: 0.0683\n",
      "Epoch 29/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0501\n",
      "Epoch 30/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0415\n",
      "Epoch 31/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0367\n",
      "Epoch 32/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9973 - loss: 0.0339\n",
      "Epoch 33/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0318\n",
      "Epoch 34/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0302\n",
      "Epoch 35/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0509\n",
      "Epoch 36/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0606\n",
      "Epoch 37/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0248\n",
      "Epoch 38/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0153\n",
      "Epoch 39/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0136\n",
      "Epoch 40/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0124\n",
      "Epoch 41/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0120\n",
      "Epoch 42/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9981 - loss: 0.0161\n",
      "Epoch 43/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0974\n",
      "Epoch 44/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9946 - loss: 0.0379\n",
      "Epoch 45/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0149\n",
      "Epoch 46/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0127\n",
      "Epoch 47/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0095\n",
      "Epoch 48/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0089\n",
      "Epoch 49/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0121\n",
      "Epoch 50/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0107\n",
      "Epoch 51/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0081\n",
      "Epoch 52/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0447\n",
      "Epoch 53/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0743\n",
      "Epoch 54/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0170\n",
      "Epoch 55/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0103\n",
      "Epoch 56/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0081\n",
      "Epoch 57/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0102\n",
      "Epoch 58/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0105\n",
      "Epoch 59/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0079\n",
      "Epoch 60/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0086\n",
      "Epoch 61/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0086\n",
      "Epoch 62/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0543\n",
      "Epoch 63/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9862 - loss: 0.0551\n",
      "Epoch 64/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9973 - loss: 0.0143\n",
      "Epoch 65/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0092\n",
      "Epoch 66/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9968 - loss: 0.0132\n",
      "Epoch 67/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0104\n",
      "Epoch 68/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0074\n",
      "Epoch 69/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0112\n",
      "Epoch 70/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0100\n",
      "Epoch 71/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0119\n",
      "Epoch 72/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0246\n",
      "Epoch 73/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9786 - loss: 0.0822\n",
      "Epoch 74/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0170\n",
      "Epoch 75/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0104\n",
      "Epoch 76/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0091\n",
      "Epoch 77/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0098\n",
      "Epoch 78/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0083\n",
      "Epoch 79/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0106\n",
      "Epoch 80/80\n",
      "\u001b[1m568/568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9973 - loss: 0.0110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a918d408fa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=80, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac52e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T16:35:05.269269Z",
     "iopub.status.busy": "2024-09-07T16:35:05.268803Z",
     "iopub.status.idle": "2024-09-07T16:35:08.135603Z",
     "shell.execute_reply": "2024-09-07T16:35:08.134654Z"
    },
    "papermill": {
     "duration": 3.535328,
     "end_time": "2024-09-07T16:35:08.137701",
     "exception": false,
     "start_time": "2024-09-07T16:35:04.602373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She went to the store of holding her tongue and if you can compass it do cure the younger girls of running after officers and if i may mention so delicate a subject endeavour to check that little something bordering on conceit and impertinence which your lady possesses have you\n"
     ]
    }
   ],
   "source": [
    "input_text = \"She went to the store\"\n",
    "predict_next_words = 45\n",
    "\n",
    "\n",
    "for _ in range(predict_next_words):\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    \n",
    "    input_sequence = input_sequence[-5:]\n",
    "    \n",
    "    input_sequence = np.array(input_sequence).reshape(1, -1)\n",
    "    \n",
    "    predicted_prob = model.predict(input_sequence, verbose=0)\n",
    "    predicted_index = np.argmax(predicted_prob, axis=-1)\n",
    "    \n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    if output_word == \"\":\n",
    "        print(\"Aucun mot prédit trouvé.\")\n",
    "        break\n",
    "    \n",
    "    input_text += \" \" + output_word\n",
    "\n",
    "print(input_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1357760,
     "sourceId": 2256379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 474.96086,
   "end_time": "2024-09-07T16:35:11.860686",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-07T16:27:16.899826",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
